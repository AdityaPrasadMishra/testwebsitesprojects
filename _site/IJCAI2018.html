<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/assets/css/style.css?v=" media="screen" type="text/css">
    <link rel="stylesheet" href="/assets/css/print.css" media="print" type="text/css">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Yochan @ Conferences</title>
<meta name="generator" content="Jekyll v3.8.3" />
<meta property="og:title" content="Yochan @ Conferences" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/IJCAI2018.html" />
<meta property="og:url" content="http://localhost:4000/IJCAI2018.html" />
<meta property="og:site_name" content="Yochan @ Conferences" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/IJCAI2018.html","headline":"Yochan @ Conferences","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="http://localhost:4000/">
          <h1>Yochan @ Conferences</h1>
        </a>
        <h2></h2>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1 id="ijcai-ecai-18-stockholm">IJCAI-ECAI-18, Stockholm</h1>
<p>The 27th International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence, the premier international gathering of researchers in AI. You can find more about the conference 
<a href="https://www.ijcai-18.org/">here</a>. Yochan have a number of accepted papers for the main event. You can find more about the proceedings for the main event <a href="https://www.ijcai.org/proceedings/2018/">here</a>.</p>

<h2 id="accepted-papers">Accepted Papers</h2>
<ul>
  <li>
    <p><a href="https://www.ijcai.org/proceedings/2018/0671.pdf"><strong>Hierarchical Expertise Level Modeling for User Specific Contrastive Explanations</strong></a></p>

    <p><strong>Authors</strong> - Sarath Sreedharan, Siddharth Srivastava, Subbarao Kambhampati</p>

    <p><strong>Abstract</strong> - There is a growing interest within the AI research
  community in developing autonomous systems capable
  of explaining their behavior to users. However,
  the problem of computing explanations for
  users of different levels of expertise has received
  little research attention. We propose an approach
  for addressing this problem by representing the
  user’s understanding of the task as an abstraction
  of the domain model that the planner uses. We
  present algorithms for generating minimal explanations
  in cases where this abstract human model
  is not known. We reduce the problem of generating
  an explanation to a search over the space of abstract
  models and show that while the complete problem
  is NP-hard, a greedy algorithm can provide good
  approximations of the optimal solution. We also
  empirically show that our approach can efficiently
  compute explanations for a variety of problems.</p>

    <p><strong>Status</strong> - Accepted for the Main Track and published in Proceedings in Planning and Scheduling section.
<br /><br /></p>
  </li>
  <li>
    <p><a href="https://www.ijcai.org/proceedings/2018/0565.pdf"><strong>Extracting Action Sequences from Texts Based on Deep Reinforcement Learning</strong></a></p>

    <p><strong>Authors</strong> - Wenfeng Feng, Hankz Hankui Zhuo, Subbarao Kambhampati</p>

    <p><strong>Abstract</strong> - Extracting action sequences from texts is challenging,
  as it requires commonsense inferences based
  on world knowledge. Although there has been
  work on extracting action scripts, instructions, navigation
  actions, etc., they require either the set of
  candidate actions be provided in advance, or action
  descriptions are restricted to a specific form,
  e.g., description templates. In this paper we aim
  to extract action sequences from texts in free natural
  language, i.e., without any restricted templates,
  provided the set of actions is unknown. We propose
  to extract action sequences from texts based on the
  deep reinforcement learning framework. Specifically,
  we view “selecting” or “eliminating” words
  from texts as “actions”, and texts associated with
  actions as “states”. We build Q-networks to learn
  policies of extracting actions and extract plans from
  the labeled texts. We demonstrate the effectiveness
  of our approach on several datasets with comparison
  to state-of-the-art approaches</p>

    <p><strong>Status</strong> - Accepted for the Main Track and published in Proceedings in Natural Language section.
<br /><br /><br /></p>
    <h2 id="accepted-demos">Accepted Demos</h2>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1709.04517.pdf"><strong>Visualizations for an Explainable Planning Agent</strong></a></p>

    <p><strong>Authors</strong> - Tathagata Chakraborti, Kshitij P. Fadnis, Kartik Talamadupula, Mishal Dholakia, Biplav Srivastava, Jeffrey O. Kephart, Rachel K. E. Bellamy</p>

    <p><strong>Abstract</strong> - In this paper, we report on the visualization capabilities
  of an Explainable AI Planning (XAIP) agent that can support human in the loop decision making. Imposing transparency and explainability requirements on such agents is especially important in order to establish trust and common ground with
  the end-to-end automated planning system. Visualizing the agent’s internal decision making processes is a crucial step towards achieving this. This may include externalizing the “brain” of the agent – starting from its sensory inputs, to progressively higher order decisions made by it in order to drive its planning components. We also show how the planner can bootstrap on the latest techniques in explainable planning to cast plan visualization as a plan explanation problem, and thus provide concise model based visualization of its plans. We demonstrate
  these functionalities in the context of the automated planning components of a smart assistant in an instrumented meeting space.</p>

    <p><strong>Demo Schedule</strong> - July 17th, afternoon</p>
  </li>
</ul>

        </section>

        <aside id="sidebar">
          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.
          <br/><br/><img style="display:inline" src="https://yochan-lab.github.io/papers/files/images/yochan_icon.png" alt=""/></p>
        </aside>
      </div>
    </div>

    
  </body>
</html>
