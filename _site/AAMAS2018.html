<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/assets/css/style.css?v=" media="screen" type="text/css">
    <link rel="stylesheet" href="/assets/css/print.css" media="print" type="text/css">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Yochan @ Conferences</title>
<meta name="generator" content="Jekyll v3.8.3" />
<meta property="og:title" content="Yochan @ Conferences" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/AAMAS2018.html" />
<meta property="og:url" content="http://localhost:4000/AAMAS2018.html" />
<meta property="og:site_name" content="Yochan @ Conferences" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/AAMAS2018.html","headline":"Yochan @ Conferences","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="http://localhost:4000/">
          <h1>Yochan @ Conferences</h1>
        </a>
        <h2></h2>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1 id="aamas-2018-stockholm">AAMAS 2018, Stockholm</h1>
<p>AAMAS (International Conference on Autonomous Agents and Multiagent Systems) 2018, the 17th edition of the conference, will be held on July 10-15, in Stockholm, Sweden and is part of the Federated AI Meeting (FAIM), with the other conferences being IJCAI, ICML, ICCBR and SoCS. More information available <a href="http://celweb.vuse.vanderbilt.edu/aamas18/">here</a>. The detailed schedule for Yochan’s participation in various tracks and events is given below.</p>

<h2 id="accepted-papers">Accepted Papers</h2>
<ul>
  <li>
    <p><a href="https://arxiv.org/pdf/1712.01949.pdf"><strong>Recognizing Plans by Learning Embeddings from Observed Action Distributions</strong></a></p>

    <p><strong>Authors</strong> - Yantian Zha, Yikang Li, Sriram Gopalakrishnan, Baoxin Li, Subbarao Kambhampati</p>

    <p><strong>Abstract</strong> - Plan recognition is essential for multi-agent collaboration, and especially for surveillance, in which the agent needs to detect or predict the actions of a perpetrator. Solving the plan recognition
  problem has been popular in the planning literature [8, 11].
  For plan recognition, there is a fair amount of work that uses
  models with various levels of completeness, i.e. with no model, shallow models, approximate models, and with full models [4]. We adopt the idea of using a shallow model to do plan recognition, and extend the work of DUP [13]. We chose to enhance DUP because it does not require an accurate domain model. DUP learns Word2Vec models which capture affinities between actions (we refer to these models as action affinity models in the rest of our paper), which are then used in plan recognition.</p>

    <p><strong>Status</strong> - Extended Abstract accepted for the Main Track Event.</p>

    <p><strong>Poster Presentation Schedule</strong> - 11th July 2018 (15:30 - 17:00)
<br /><br /></p>
  </li>
  <li>
    <p><a href="http://rakaposhi.eas.asu.edu/paper_files/aamas18-emergent-behaviors.pdf"><strong>Balancing Explicability and Explanations - Emergent Behaviors in Human-Aware Planning</strong></a></p>

    <p><strong>Authors</strong> - Tathagata Chakraborti, Sarath Sreedharan, Subbarao Kambhampati</p>

    <p><strong>Abstract</strong> - Human aware planning requires an agent to be aware of the intentions, capabilities and mental model of the human in the loop during its decision process. This can involve generating plans that are explicable to a human observer as well as the ability to provide explanations when such plans cannot be generated. In this paper, we bring these two concepts together and show how an agent can account for both these needs and achieve a trade-off during the plan
  generation process itself by means of a model-space search method MEGA. This in effect provides a comprehensive perspective of what it means for a decision-making agent to be “human-aware” by bringing together existing principles of planning under the umbrella of a single plan generation process. We situate our discussion in the context of recent work on explicable planning and explanation generation, and illustrate these concepts in modified versions of two well-known planning domains, as well as in a demonstration
  of a robot involved in a typical search and reconnaissance task with an external supervisor. Human factor studies in the latter highlight the usefulness of the proposed approaches.</p>

    <p><strong>Status</strong> - Extended Abstract accepted for the Robotics Track Event.</p>

    <p><strong>Poster Presentation Schedule</strong> - 13th July 2018 (15:30 - 17:00)</p>
  </li>
</ul>

        </section>

        <aside id="sidebar">
          

          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.
          <br/><br/><img style="display:inline" src="https://yochan-lab.github.io/papers/files/images/yochan_icon.png" alt=""/></p>
        </aside>
      </div>
    </div>

    
  </body>
</html>
