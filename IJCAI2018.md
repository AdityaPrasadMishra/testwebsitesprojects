---
layout: default
---
# IJCAI-ECAI-18, Stockholm
The 27th International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence, the premier international gathering of researchers in AI. You can find more about the conference 
[here](https://www.ijcai-18.org/). Yochan have a number of accepted papers for the main event. You can find more about the proceedings for the main event [here](https://www.ijcai.org/proceedings/2018/).

## Accepted Papers
* [**Hierarchical Expertise Level Modeling for User Specific Contrastive Explanations**](https://www.ijcai.org/proceedings/2018/0671.pdf)

    **Authors** - Sarath Sreedharan, Siddharth Srivastava, Subbarao Kambhampati

    **Abstract** - There is a growing interest within the AI research
    community in developing autonomous systems capable
    of explaining their behavior to users. However,
    the problem of computing explanations for
    users of different levels of expertise has received
    little research attention. We propose an approach
    for addressing this problem by representing the
    user’s understanding of the task as an abstraction
    of the domain model that the planner uses. We
    present algorithms for generating minimal explanations
    in cases where this abstract human model
    is not known. We reduce the problem of generating
    an explanation to a search over the space of abstract
    models and show that while the complete problem
    is NP-hard, a greedy algorithm can provide good
    approximations of the optimal solution. We also
    empirically show that our approach can efficiently
    compute explanations for a variety of problems.

    **Status** - Accepted for the Main Track and published in Proceedings in Planning and Scheduling section.
<br/><br/>

* [**Extracting Action Sequences from Texts Based on Deep Reinforcement Learning**](https://www.ijcai.org/proceedings/2018/0565.pdf)

    **Authors** - Wenfeng Feng, Hankz Hankui Zhuo, Subbarao Kambhampati

    **Abstract** - Extracting action sequences from texts is challenging,
    as it requires commonsense inferences based
    on world knowledge. Although there has been
    work on extracting action scripts, instructions, navigation
    actions, etc., they require either the set of
    candidate actions be provided in advance, or action
    descriptions are restricted to a specific form,
    e.g., description templates. In this paper we aim
    to extract action sequences from texts in free natural
    language, i.e., without any restricted templates,
    provided the set of actions is unknown. We propose
    to extract action sequences from texts based on the
    deep reinforcement learning framework. Specifically,
    we view “selecting” or “eliminating” words
    from texts as “actions”, and texts associated with
    actions as “states”. We build Q-networks to learn
    policies of extracting actions and extract plans from
    the labeled texts. We demonstrate the effectiveness
    of our approach on several datasets with comparison
    to state-of-the-art approaches

    **Status** - Accepted for the Main Track and published in Proceedings in Natural Language section.
<br/><br/><br/>
## Accepted Demos

* [**Visualizations for an Explainable Planning Agent**](https://arxiv.org/pdf/1709.04517.pdf) 

    **Authors** - Tathagata Chakraborti, Kshitij P. Fadnis, Kartik Talamadupula, Mishal Dholakia, Biplav Srivastava, Jeffrey O. Kephart, Rachel K. E. Bellamy

    **Abstract** - In this paper, we report on the visualization capabilities
    of an Explainable AI Planning (XAIP) agent that can support human in the loop decision making. Imposing transparency and explainability requirements on such agents is especially important in order to establish trust and common ground with
    the end-to-end automated planning system. Visualizing the agent’s internal decision making processes is a crucial step towards achieving this. This may include externalizing the “brain” of the agent – starting from its sensory inputs, to progressively higher order decisions made by it in order to drive its planning components. We also show how the planner can bootstrap on the latest techniques in explainable planning to cast plan visualization as a plan explanation problem, and thus provide concise model based visualization of its plans. We demonstrate
    these functionalities in the context of the automated planning components of a smart assistant in an instrumented meeting space.

    **Demo Schedule** - July 17th, afternoon